---
layout: post
title: deep-learning-theory-post5
description: >
  
sitemap: false
hide_last_modified: true
categories:
  - deep-learning
  - theory
---

## 내가 다시 보려고 만든 "밑바닥 부터 시작하는 딥러닝" 정리 3

책 "밑바닥부터 시작하는 딥러닝 1권" 내용 중 다시 보려고 만든 자료입니다. (챕터 5)

### chapter 5

- 챕터 4에서는 신경망 학습에 대해서 설명했다. 그때 신경망의 가중치 매개변수의 기울기(정확히는 가중치 매개변수에 대한 손실 함수의 기울기)는 수치 미분을 사용해 구했다.
- 이번 챕터에서는 가중치 매개변수의 기울기를 효율적으로 계산하는 "오차역전파법(backpropagation)"을 배워보겠다.
- 순전파는 계산 그래프의 출발점부터 종착점으로의 전파이고, 역전파는 반대방향 전파이다. 역전파는 이후에 미분을 계산할 때 중요한 역할을 한다.

### chapter 5.1.2 국소적 계산

- 계산 그래프는 국소적 계산에 집중한다.
- 국소적인 계산은 단순하지만, 그 결과를 전달함으로써 전체를 구성하는 복잡한 계산을 해낼 수 있다.

### chapter 5.1.3 왜 계산 그래프로 푸는가 ?

- 첫 번째, '국소적 계산' 때문
- 두 번째, 계산 그래프는 중간 계산 결과를 모두 보관할 수 있다.
- 세 번째, 실제 계산 그래프를 사용하는 가장 큰 이유는 역전파를 통해 '미분'을 효율적으로 계산할 수 있는 점에 있다. 중간까지 구한 미분 결과를 공유할 수 있어서 다수의 미분을 효율적으로 계산할 수 있다. 이처럼 계산 그래프의 이점은 순전파와 역전파를 활용해서 각 변수의 미분을 효율적으로 구할 수 있다는 것이다.

### chapter 5.2 연쇄법칙

- '국소적 미분'을 전달하는 원리는 <strong>연쇄법칙</strong>에 따른 것이다.
- 연쇄법칙은 합성 함수의 미분에 대한 성질이며, "합성 함수의 미분은 합성 함수를 구성하는 각 함수의 미분의 곱으로 나타낼 수 있다."라는 정의를 가진다.







